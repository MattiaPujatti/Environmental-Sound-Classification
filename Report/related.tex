% !TEX root = report.tex

\section{Related Work}
\label{sec:related_work}

In recent years, audio recognition systems have gained so much popularity in the machine learning world, mainly because of the developments in the artificial intelligence field. However, the research has focused mostly on speech recognition tasks, music classification and acoustic scene classification, while identification of environmental sounds was took less in consideration. One of the main reasons for this, as anticipated, was the scarcity of suitable and publicly available datasets. But when, in 2015, K. Piczak realized and made public a collection of 2000 environmental short sound clips, under the name of ESC-50 dataset \cite{piczak2015dataset}, people's interest started rising again, together with a sort of "competition", in which many classification methods were applied in order to obtain the higher accuracy over it. In the github page of the author \cite{piczakgithub} there is, in fact, a table summarizing more than 30 papers written on top of ESC-50, each of them proposing a different approach to classify those sounds. Piczak itself, in its first papers \cite{piczak2015dataset}, suggested the usage of a few "canonical" machine learning classifiers (mostly based on features extraction), and compared the results with the ones obtained from a set of human participants. Moreover, in a second paper \cite{piczak_cnn}, proposed instead the employment of convolutional neural networks, to be applied over the spectrograms derived from the clips: apparently, this approach outperformed the baseline implementation and, in fact, defined the new state of the art for environmental sound classification.\\
In the table mentioned earlier, collecting all the recent developments for this specific task and exploiting ESC-50, several different approaches are proposed: many of them are based on speech recognition-like models (MFCC coefficients, \cite{piczak2015dataset, freitag2017}), while many others are improved version of the CNN implementations (different representations, architectures, preprocessing phases \cite{Huzaifah17, soundnet, boddapati2017, aclnet, ensemble_stacked_cnn}). The head of the ranking is entirely covered by the second type of technique, that apparently outperforms the first one from any point of view. Also, many of the methods listed, rely on pretrained models, ad-hoc data augmentation and very complex architectures, mostly realized combining different machine learning prototypes. Actually, only a few approaches, all based on CNNs, are able to overcome the human classification accuracy ($81.30\%$) over ESC-50, with the best model reaching even the $94\%$ of correctly classified samples. Features extraction models, instead, appear much less frequently in the table (people started losing interest versus them) and they can all be found under the humans' accuracy threshold (the best result, $64.30\%$, was achieved exploiting the combination of a RNN autoencoder and a Multi-Layer Perceptron \cite{freitag2017}).