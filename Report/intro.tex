% !TEX root = report.tex

\section{Introduction}
\label{sec:introduction}

The actual state of the art for Environmental Sound Classification foresees the usage of Convolutional Neural Networks over datasets constructed collecting all the spectrograms derived from the audio clips. The main reason is that several architectures have been proven to outperform all the approaches based on high-level audio feature extraction.\\
In this work, however, we have developed a feature extraction technique that allows to reach quite nice scores that, merged with the higher speed of the method and the less memory consumption, could represent a gratifying alternative to CNNs and maybe deserve a closer analysis.\\
Lots of effort was dedicated, during the years, in order to develop always more precise and efficient audio classification models, via the analysis of Mel coefficients and spectrograms. However, these kind of researches were almost all dedicated to speech recognition tasks, that, nowadays, have much more relevance in our technological society, mainly because of the interactions among humans and devices. But, since most of the interest of the scientific community was "limited" on making machines to learn human language, a definitive and efficient approach for generic sound classification assignments is still missing. More precisely, environmental sound classification was so put aside, that there are only a few public available datasets of a decent dimension (\cite{piczak2015dataset, urbansound8k}).\\
The purpose of this project will be to provide an efficient way, using machine learning techniques, to classify environmental sound clips belonging to one of those collections, called ESC-50 \cite{piczak2015dataset}. Several approaches have been tested over it during the years, but only a few of them were able to reproduce, or even overcome, the human classification accuracy, estimated around 81.30\%.\\
The analysis will be organized in the following way: since the very first approaches were mainly focused on the examination of audio features, that one could extract from raw audio files, we will provide a way to collect and organize all those "vectors of features", and use them to distinguish among different classes. Then, different classification architectures and techniques will be implemented and compared among each other, in order also to show how they effectively react to different data manipulation (in term of overfitting, numerical stability, etc.). In the second part, instead, it will be shown that all those feature classifiers, without exceptions, underperform when compared to the results provided by the usage of Convolutional Neural Networks directly on audio signals and relative spectrograms (so without any kind of feature extraction), and how this new approach opened for a large number of opportunities in term of models with high accuracy in sound classification.\\